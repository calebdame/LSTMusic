{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Music RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_HaCF0y2YpwU"
   },
   "outputs": [],
   "source": [
    "%run ./helper_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "lr = 0.001\n",
    "data_size = 150\n",
    "batch_size = 256*2\n",
    "embedding_dim = 32\n",
    "data_folder = \"./mozart_sonatas/\"\n",
    "save_folder = 'V4'\n",
    "model_name = \"lstm_model\"\n",
    "\n",
    "filepath = f\"./{save_folder}/{model_name}_epoch{e}.mid\"\n",
    "\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    '''\n",
    "    Recurrent Neural Network Class with LSTM Layers\n",
    "    \n",
    "    Architecture:\n",
    "    \n",
    "                     INPUT\n",
    "                       |\n",
    "          ____LSTM Layers Output_____\n",
    "         /             |             \\\n",
    "     4 layers      3 layers      4 layers\n",
    "     w/ Relu       w/ Relu       w/ Relu\n",
    "        |              |             |\n",
    "      Offset   --->  Concat  <---  Length\n",
    "     Softmax           |           Softmax\n",
    "        |          3 layers          |\n",
    "        |          w/ Relu           |\n",
    "        |              |             |\n",
    "        |            Note            |\n",
    "        |           Softmax          |\n",
    "        |              |             |   \n",
    "         \\__________Concat__________/\n",
    "                       |\n",
    "                    OUTPUT\n",
    "    '''\n",
    "    def __init__(self,sizes,embedding_dim):\n",
    "        \"\"\"\n",
    "        Init. everything\n",
    "        \"\"\"\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = 256\n",
    "        self.num_layers = 3\n",
    "        self.dropout = .1\n",
    "        self.notes_vocab_size = sizes[0]\n",
    "        self.offset_vocab_size = sizes[1]\n",
    "        self.len_vocab_size = sizes[2]\n",
    "        self.embedding = nn.Embedding(sizes[0] + sizes[1] + sizes[2], embedding_dim)\n",
    "        self.lstm = nn.LSTM(input_size = embedding_dim, \n",
    "                            hidden_size = self.hidden_size, num_layers = self.num_layers, \n",
    "                           batch_first = True, dropout = self.dropout)\n",
    "        self.batch1 = nn.BatchNorm1d(self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout)\n",
    "        \n",
    "        self.linear1a = nn.Linear(self.hidden_size, self.notes_vocab_size)\n",
    "        self.linear2a = nn.Linear(self.notes_vocab_size, self.notes_vocab_size*2)\n",
    "        self.linear3a = nn.Linear(self.notes_vocab_size*2, self.notes_vocab_size)\n",
    "        self.linear4a = nn.Linear(np.sum(sizes), 2*np.sum(sizes))\n",
    "        self.linear5a = nn.Linear(2*np.sum(sizes), self.notes_vocab_size)\n",
    "        self.linear6a = nn.Linear(self.notes_vocab_size, self.notes_vocab_size)\n",
    "        \n",
    "        self.linear1b = nn.Linear(self.hidden_size, self.offset_vocab_size)\n",
    "        self.linear2b = nn.Linear(self.offset_vocab_size, self.offset_vocab_size*2)\n",
    "        self.linear3b = nn.Linear(self.offset_vocab_size*2, self.offset_vocab_size)\n",
    "        self.linear4b = nn.Linear(self.offset_vocab_size, self.offset_vocab_size)\n",
    "        \n",
    "        self.linear1c = nn.Linear(self.hidden_size, self.len_vocab_size)\n",
    "        self.linear2c = nn.Linear(self.len_vocab_size, self.len_vocab_size*2)\n",
    "        self.linear3c = nn.Linear(self.len_vocab_size*2, self.len_vocab_size)\n",
    "        self.linear4c = nn.Linear(self.len_vocab_size, self.len_vocab_size)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.Lrelu = nn.LeakyReLU()\n",
    "        self.softmax = nn.LogSoftmax(dim = 1)\n",
    "\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        embeds = self.embedding(x)\n",
    "        \n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        out = self.dropout(self.batch1(lstm_out[:,-1]))\n",
    "        out = self.relu(self.linear1a(out))\n",
    "        out = self.relu(self.linear2a(out))\n",
    "        half_done = self.relu(self.linear3a(out))\n",
    "        \n",
    "        out = self.dropout(self.batch1(lstm_out[:,-1]))\n",
    "        out = self.relu(self.linear1b(out))\n",
    "        out = self.relu(self.linear2b(out))\n",
    "        out = self.relu(self.linear3b(out))\n",
    "        out = self.linear4b(out)\n",
    "        offset_pred = self.softmax(out)\n",
    "        \n",
    "        out = self.dropout(self.batch1(lstm_out[:,-1]))\n",
    "        out = self.relu(self.linear1c(out))\n",
    "        out = self.relu(self.linear2c(out))\n",
    "        out = self.relu(self.linear3c(out))\n",
    "        out = self.linear4c(out)\n",
    "        len_pred = self.softmax(out)\n",
    "        \n",
    "        out = self.relu(self.linear4a(torch.cat((len_pred, offset_pred, half_done) ,1)))\n",
    "        out = self.relu(self.linear5a(out))\n",
    "        note_pred = self.softmax(self.linear6a(out))\n",
    "        \n",
    "        return torch.cat((note_pred, offset_pred, len_pred), 1), hidden\n",
    "  \n",
    "\n",
    "    def initHidden(self,batch_size):\n",
    "        # initialize the hidden layers\n",
    "        weight = next(self.parameters()).data\n",
    "        h0 = weight.new(self.num_layers, batch_size, self.hidden_size).zero_().to(device)\n",
    "        h1 = weight.new(self.num_layers, batch_size, self.hidden_size).zero_().to(device)\n",
    "        return (h0, h1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hEpK4GIyZCWg",
    "outputId": "1eec99da-8c38-41af-f676-2f391be7113b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:38<00:00,  1.94s/it]\n"
     ]
    }
   ],
   "source": [
    "raw_notes, raw_offsets, raw_length = music_to_lists(data_folder)\n",
    "notes, offsets, length = clean_lists(raw_notes, raw_offsets, raw_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "UghZuJfxZuzO"
   },
   "outputs": [],
   "source": [
    "note_dict = make_unique_map(notes)\n",
    "len_dict = make_unique_map(length)\n",
    "offset_dict = make_unique_map(offsets)\n",
    "\n",
    "num_len = [len_dict[round(i,4)] for i in length]\n",
    "num_notes = [note_dict[i] for i in notes]\n",
    "num_offset = [offset_dict[round(i,4)] for i in offsets]\n",
    "\n",
    "#Create model for \n",
    "TestLoader, TrainLoader, X_train, X_test, y_train, y_test = loadData(data_size, batch_size, [num_notes, num_offset, num_len])\n",
    "for i in range(len(y_train)):\n",
    "    y_train[i][1] += len(note_dict)\n",
    "    y_train[i][2] += len(offset_dict) + len(note_dict)\n",
    "for i in range(len(y_test)):\n",
    "    y_test[i][1] += len(note_dict)\n",
    "    y_test[i][2] += len(offset_dict) + len(note_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sizes = (len(set(num_notes)),len(set(num_offset)),len(set(num_len)))\n",
    "model = RNN(sizes,embedding_dim = embedding_dim).to(device)\n",
    "optimizer = torch.optim.RMSprop(model.parameters(),lr = lr)\n",
    "objective = nn.BCEWithLogitsLoss()\n",
    "\n",
    "nacc, oacc, lacc = [], [], []\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "id": "0mG_MoUs2E1a",
    "outputId": "78c79763-5558-4977-f2d3-89a36c03ac04",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170it [10:36,  3.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, \n",
      "loss: 6.642864025921239e-06, \n",
      "test note accuracy: 0.3874782986111111,\n",
      "test offset accuracy: 0.8918185763888888,\n",
      "test length accuracy: 0.7743055555555556\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "119it [07:32,  3.57s/it]"
     ]
    }
   ],
   "source": [
    "for e in range(43,  epochs):\n",
    "    model.train()\n",
    "    loss_val = 0\n",
    "    for batch, (x, y) in tqdm(enumerate(TrainLoader), position=0, leave= True):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        y_full = torch.zeros(y.shape[0], np.sum(sizes))\n",
    "        for i in range(y.shape[0]):\n",
    "            for k in y[i]:\n",
    "                y_full[i][k] = 1\n",
    "        \n",
    "        (h0,h1) = model.initHidden(batch_size)\n",
    "\n",
    "        optimizer.zero_grad() #zero the gradient\n",
    "        outputs, (h0,h1) = model(x,(h0,h1)) #forward pass\n",
    "\n",
    "        h0 = h0.detach()\n",
    "        h1 = h1.detach()\n",
    "        loss = objective(outputs, y_full) #get loss\n",
    "        loss_val += loss.item()\n",
    "        loss.backward() #backward pass\n",
    "        nn.utils.clip_grad_norm_(model.parameters(),5)\n",
    "        optimizer.step() #update model\n",
    "        \n",
    "    losses.append(loss_val/(len(TrainLoader)*batch_size))\n",
    "    model.eval()\n",
    "    nacc.append(0)\n",
    "    lacc.append(0)\n",
    "    oacc.append(0)\n",
    "    for batch, (x,y) in enumerate(TestLoader):\n",
    "        h0, h1 = model.initHidden(batch_size)\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device).cpu().numpy()\n",
    "       \n",
    "        out, h = model(x, (h0,h1))\n",
    "        out = out.detach().cpu().numpy()\n",
    "\n",
    "        y_note = np.argmax(out[:,:sizes[0]], axis=1)\n",
    "        y_off = np.argmax(out[:,sizes[0]:sizes[1]+sizes[0]], axis=1) + sizes[0]\n",
    "        y_len = np.argmax(out[:,sizes[0] + sizes[1]:], axis=1) + sizes[1] + sizes[0]\n",
    "\n",
    "        nacc[-1] += np.mean(y_note == y[:,0])\n",
    "        oacc[-1] += np.mean(y_off == y[:,1])\n",
    "        lacc[-1] += np.mean(y_len == y[:,2])\n",
    "\n",
    "        \n",
    "    nacc[-1] /= len(TestLoader)\n",
    "    lacc[-1] /= len(TestLoader)\n",
    "    oacc[-1] /= len(TestLoader)\n",
    "\n",
    "\n",
    "    torch.save({\n",
    "        'epoch': e,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,},\n",
    "    f\"./{save_folder}/{model_name}_epoch{e}.pt\")\n",
    "tm/\n",
    "    #print(f\"Epoch {e+1}, loss: {losses[-1]}, test note accuracy: {nacc[-1]},\\ntest offset accuracy: {oacc[-1]},\\ntest length accuracy: {lacc[-1]}\")\n",
    "    print(f\"Epoch {e}, \\nloss: {losses[-1]}, \\ntest note accuracy: {nacc[-1]},\\ntest offset accuracy: {oacc[-1]},\\ntest length accuracy: {lacc[-1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of rnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
