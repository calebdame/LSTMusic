{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "328b3931",
   "metadata": {},
   "source": [
    "# Load models to run predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758eeeb8",
   "metadata": {},
   "source": [
    "### Run helper functions to generate the data again\n",
    "\n",
    "If you want, you can always save out the dictionaries and the Loaders, but when it takes only 30 seconds to generate them, and this is just for fun, it would probably just be a waste of storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8720ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./helper_functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f84bcde",
   "metadata": {},
   "source": [
    "### Specifics to the model in question\n",
    "We'll need all the info we originally had to prepare the data and save out the file, like `data_folder`, `save_folder`, `model_name`, `embedding_dim` and the data and batch sizes.  In addition to what we had before, we need the `epoch` (int) that we want to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935744ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"./mozart_sonatas/\"\n",
    "save_folder = 'V4'\n",
    "model_name = \"lstm_model\"\n",
    "epoch = 30\n",
    "data_size = 150\n",
    "batch_size = 256*4\n",
    "embedding_dim = 32\n",
    "\n",
    "filepath = f\"./{save_folder}/{model_name}_epoch{epoch}.mid\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4bfbd3",
   "metadata": {},
   "source": [
    "### Generate the tensors / dictionaries again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b2e837",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_notes, raw_offsets, raw_length = music_to_lists(data_folder)\n",
    "notes, offsets, length = clean_lists(raw_notes, raw_offsets, raw_length)\n",
    "\n",
    "note_dict = make_unique_map(notes)\n",
    "len_dict = make_unique_map(length)\n",
    "offset_dict = make_unique_map(offsets)\n",
    "\n",
    "num_len = [len_dict[round(i,4)] for i in length]\n",
    "num_notes = [note_dict[i] for i in notes]\n",
    "num_offset = [offset_dict[round(i,4)] for i in offsets]\n",
    "\n",
    "#Create model for \n",
    "TestLoader, TrainLoader, X_train, X_test, y_train, y_test = loadData(data_size, batch_size, [num_notes, num_offset, num_len])\n",
    "for i in range(len(y_train)):\n",
    "    y_train[i][1] += len(note_dict)\n",
    "    y_train[i][2] += len(offset_dict) + len(note_dict)\n",
    "for i in range(len(y_test)):\n",
    "    y_test[i][1] += len(note_dict)\n",
    "    y_test[i][2] += len(offset_dict) + len(note_dict)\n",
    "    \n",
    "sizes = (len(set(num_notes)),len(set(num_offset)),len(set(num_len)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6010c89e",
   "metadata": {},
   "source": [
    "### Fun part: Load the model\n",
    "\n",
    "The below function not only returns the loaded model, but also the objective function and the optimizer.  That means, if you want to keep training, you can!  Otherwise, it is set to `.eval()` before being returned as a precaution since it will likely just be used for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3329056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_RNN(filepath, embedding_dim, sizes):\n",
    "    # instatiate RNN object\n",
    "    model = RNN(sizes,embedding_dim = embedding_dim)\n",
    "    \n",
    "    # load dictionary of params\n",
    "    checkpoint = torch.load(filepath)\n",
    "    \n",
    "    # load attributes and instantiate objective + optimizer\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    last_epoch = checkpoint['epoch'] # just to check that its the right one\n",
    "    last_loss = checkpoint['loss']\n",
    "    objective = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    return model, objective, optimizer, last_loss, last_epoch\n",
    "\n",
    "model, objective, optimizer, _, _ = load_RNN(filepath, embedding_dim, sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3dda32",
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = list(TestLoader) #points to test\n",
    "rand_index = np.random.randint(0,len(tester)) #choose an index\n",
    "reverse_mapping = {\"note\" : {note_dict[k]:k for k in note_dict},\n",
    "                   \"off\" : {offset_dict[k]:k for k in offset_dict},\n",
    "                   \"len\" : {len_dict[k]:k for k in len_dict}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f785c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(more_notes, sizes, model, criterion, optimizer, test_loader, reverse_mapping, rand_choice=None):\n",
    "    preds = []\n",
    "    if rand_choice is None: #\n",
    "        rand_choice = np.random.randint(0,len(tester))\n",
    "    rand_index = np.random.randint(0,127)\n",
    "    temp_data = tester[rand_choice][0][rand_index].reshape(1,-1)\n",
    "    og_data = temp_data\n",
    "    H = model.initHidden(1) #get the hidden states\n",
    "    \n",
    "    while len(preds) < more_notes*len(sizes):\n",
    "        \n",
    "        output, H = model(temp_data, H) #find the output\n",
    "        p = torch.argmax(output[0][:sizes[0]]) #find the location of the largest\n",
    "        q = torch.argmax(output[0][sizes[0]:sizes[0] + sizes[1]])\n",
    "        r = torch.argmax(output[0][sizes[0] + sizes[1]:])\n",
    "        p, q, r = torch.flatten(p),torch.flatten(q+sizes[0]),torch.flatten(r+sizes[0] +sizes[1])\n",
    "        preds += list(p.numpy()) + list(q.numpy()) + list(r.numpy()) #get the predictions\n",
    "        temp_data = torch.cat((temp_data.squeeze(),p,q,r))\n",
    "        temp_data = temp_data[len(sizes):].unsqueeze(0).reshape(1,-1)\n",
    "\n",
    "    pred_note = [reverse_mapping[\"note\"][p] for p in og_data[:rand_index].numpy()[0][::3]] + [reverse_mapping[\"note\"][p] for p in preds[::3]]\n",
    "    pred_off = [reverse_mapping[\"off\"][p-sizes[0]] for p in og_data[:rand_index].numpy()[0][1::3]] + [reverse_mapping[\"off\"][p-sizes[0]] for p in preds[1::3]]\n",
    "    pred_len = [reverse_mapping[\"len\"][p-sizes[0] - sizes[1]] for p in og_data[:rand_index].numpy()[0][2::3]] + [reverse_mapping[\"len\"][p-sizes[0]-sizes[1]] for p in preds[2::3]]\n",
    "    \n",
    "    \n",
    "    return pred_note, pred_off, pred_len\n",
    "more_notes = 600\n",
    "pred_note, pred_off, pred_len = predict(more_notes, sizes, model, objective, optimizer, TestLoader, reverse_mapping)\n",
    "len(pred_note), len(pred_off), len(pred_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77a2ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_comp = []\n",
    "previous_offset = 0\n",
    "for i in range(len(pred_note)):\n",
    "\n",
    "    if '.' in pred_note[i]:\n",
    "        chord_pitches = pred_note[i].split('.')\n",
    "        notes = []\n",
    "        for pitch in chord_pitches:\n",
    "            new_note = note.Note(pitch)\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            notes.append(new_note)\n",
    "        new_chord = chord.Chord(notes)\n",
    "        new_chord.offset = pred_off[i] + previous_offset\n",
    "        new_chord.duration.quarterLength = pred_len[i]\n",
    "        new_comp.append(new_chord)\n",
    "    \n",
    "    else:\n",
    "        new_note = note.Note(pred_note[i])\n",
    "        new_note.storedInstrument = instrument.Piano()\n",
    "        new_note.offset = pred_off[i] + previous_offset\n",
    "        new_note.duration.quarterLength = pred_len[i]\n",
    "        new_comp.append(new_note)\n",
    "    \n",
    "    previous_offset += pred_off[i]\n",
    "\n",
    "midi_stream = stream.Stream(new_comp)\n",
    "midi_stream.write('midi', fp='song.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e7817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_comp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
