{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a389ed6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import converter, instrument, note, chord, stream, midi\n",
    "import glob\n",
    "import os\n",
    "import gzip\n",
    "import tarfile    \n",
    "from torchvision import datasets                  \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e5acde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(filepath):\n",
    "    if not os.path.exists(os.path.join(filepath, 'mozart_sonatas.tar.gz')):\n",
    "        datasets.utils.download_url('https://github.com/Foundations-of-Applied-Mathematics/Data/raw/master/RNN/mozart_sonatas.tar.gz', filepath, 'mozart_sonatas.tar.gz', None)\n",
    "\n",
    "    print('Extracting {}'.format('mozart_sonatas.tar.gz'))\n",
    "    gzip_path = os.path.join(filepath, 'mozart_sonatas.tar.gz')\n",
    "    with open(gzip_path.replace('.gz', ''), 'wb') as out_f, gzip.GzipFile(gzip_path) as zip_f:\n",
    "        out_f.write(zip_f.read())\n",
    "\n",
    "    print('Untarring {}'.format('mozart_sonatas.tar'))\n",
    "    tar_path = os.path.join(filepath,'mozart_sonatas.tar')\n",
    "    z = tarfile.TarFile(tar_path)\n",
    "    z.extractall(tar_path.replace('.tar', ''))\n",
    "    \n",
    "def music_to_lists(filepath):\n",
    "    \"\"\" =\n",
    "    filepath: str, path to the .mid files\n",
    "    in my case this path is:    \"/content/drive/MyDrive/mozart_sonatas/mozart_sonatas\"\n",
    "    RETURNS: \n",
    "            list of 119348 pitches.    \n",
    "    \"\"\"\n",
    "    myNotes, myOffsets, myDurations = [], [], []\n",
    "    #open the file \n",
    "    dirs = os.listdir(filepath)\n",
    "    for sonata in tqdm(dirs): \n",
    "        path = filepath+\"/\"+sonata\n",
    "        #Read the file\n",
    "        midi = converter.parse(path)\n",
    "        notes_to_parse = instrument.partitionByInstrument(midi).parts[0].recurse()\n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                mystr = str(element.pitch)\n",
    "                myNotes.append(mystr)\n",
    "                myOffsets.append(str(element.offset))\n",
    "                myDurations.append(str(element.duration.quarterLength))\n",
    "            \n",
    "            elif isinstance(element, chord.Chord): \n",
    "                mystr = \"\"\n",
    "                for thisnote in element.pitches:\n",
    "                    mystr += str(thisnote)\n",
    "                    mystr += '.'\n",
    "                mystr = mystr[:-1] #cut off the last period \n",
    "                myNotes.append(mystr)\n",
    "                myOffsets.append(str(element.offset))\n",
    "                myDurations.append(str(element.duration.quarterLength))\n",
    "\n",
    "    return myNotes, myOffsets, myDurations\n",
    "                \n",
    "                \n",
    "def clean_lists(notes, offsets, lengths):\n",
    "    new_notes, new_offsets, new_lengths = [], [] , []\n",
    "    offsets = [eval(i) for i in offsets]\n",
    "    lengths = [eval(i) for i in lengths]\n",
    "\n",
    "\n",
    "    notes = [notes[i] for i in range(len(notes)) if lengths[i] > 0]\n",
    "    offsets = [offsets[i] for i in range(len(offsets)) if lengths[i] > 0]\n",
    "    lengths = [lengths[i] for i in range(len(lengths)) if lengths[i] > 0]\n",
    "\n",
    "    first = True\n",
    "    first_note_offset = 0\n",
    "    \n",
    "    for i in range(len(notes)):\n",
    "        \n",
    "        if lengths[i] > 4:\n",
    "            lengths[i] = 4\n",
    "        if first:\n",
    "            first = False\n",
    "            temp = first_note_offset\n",
    "        elif abs(offsets[i] - offsets[i-1]) > 8:\n",
    "                temp = first_note_offset\n",
    "        else:\n",
    "                temp = offsets[i-1]\n",
    "        if (i > 0) and (notes[i] == \"REST\") and (notes[i-1] == \"REST\") and (lengths[i] > 0) and (lengths[i-1] > 0):\n",
    "            continue\n",
    "            \n",
    "        new_offsets += [offsets[i] - temp if offsets[i] - temp < 8 else 8]\n",
    "        new_lengths += [lengths[i]]\n",
    "        new_notes += [notes[i]]\n",
    "    \n",
    "    return new_notes, [i if i <=4 else 4 for i in new_offsets], new_lengths \n",
    "\n",
    "def make_unique_map(somelist):\n",
    "    somedict = dict()\n",
    "    if not isinstance(somelist[0],str) :\n",
    "        somelist = [round(i,4) for i in somelist]\n",
    "    for i,n in enumerate(np.unique(somelist)):\n",
    "            somedict[n] = i\n",
    "    return somedict\n",
    "\n",
    "def loadData(data_size, batch_size, lists, test_size=0.1):\n",
    "    scale = len(lists)\n",
    "    all_data =    [[lists[j][i] for j in range(scale)] for i in range(len(lists[0]))]\n",
    "    flat_list = [item for sublist in all_data for item in sublist]\n",
    "    data = torch.LongTensor(flat_list)\n",
    "    labels = [data[scale*i:data_size+scale*i] for i in range(int(len(data)/scale - data_size/scale))]\n",
    "    sequences = [data[data_size+scale*i:data_size+scale*(i+1)] for i in range(int(len(data)/scale - data_size/scale))]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split( labels, sequences,test_size = test_size)\n",
    "\n",
    "    tens_data_train = []\n",
    "    tens_data_test= []\n",
    "    for x,y in zip(X_train, y_train):\n",
    "            tens_data_train.append([x,y])\n",
    "    for x,y in zip(X_test, y_test):\n",
    "            tens_data_test.append([x,y])\n",
    "    TrainLoader = DataLoader(tens_data_train,shuffle = True,drop_last=True,batch_size = batch_size)\n",
    "    TestLoader = DataLoader(tens_data_test,drop_last = True,batch_size = batch_size)\n",
    "    return TestLoader, TrainLoader, X_train, X_test, y_train, y_test\n",
    "\n",
    "def predict(more_notes, sizes, model, criterion, optimizer, test_loader, reverse_mapping, rand_choice=None):\n",
    "    preds = []\n",
    "    if rand_choice is None: #\n",
    "        rand_choice = np.random.randint(0,len(tester))\n",
    "    rand_index = np.random.randint(0,127)\n",
    "    temp_data = tester[rand_choice][0][rand_index].reshape(1,-1)\n",
    "    og_data = temp_data\n",
    "    H = model.initHidden(1) #get the hidden states\n",
    "    \n",
    "    while len(preds) < more_notes*len(sizes):\n",
    "        \n",
    "        output, H = model(temp_data, H) #find the output\n",
    "        p = torch.argmax(output[0][:sizes[0]]) #find the location of the largest\n",
    "        q = torch.argmax(output[0][sizes[0]:sizes[0] + sizes[1]])\n",
    "        r = torch.argmax(output[0][sizes[0] + sizes[1]:])\n",
    "        p, q, r = torch.flatten(p),torch.flatten(q+sizes[0]),torch.flatten(r+sizes[0] +sizes[1])\n",
    "        preds += list(p.numpy()) + list(q.numpy()) + list(r.numpy()) #get the predictions\n",
    "        temp_data = torch.cat((temp_data.squeeze(),p,q,r))\n",
    "        temp_data = temp_data[len(sizes):].unsqueeze(0).reshape(1,-1)\n",
    "\n",
    "    pred_note = [reverse_mapping[\"note\"][p] for p in og_data[:rand_index].numpy()[0][::3]] + [reverse_mapping[\"note\"][p] for p in preds[::3]]\n",
    "    pred_off = [reverse_mapping[\"off\"][p-sizes[0]] for p in og_data[:rand_index].numpy()[0][1::3]] + [reverse_mapping[\"off\"][p-sizes[0]] for p in preds[1::3]]\n",
    "    pred_len = [reverse_mapping[\"len\"][p-sizes[0] - sizes[1]] for p in og_data[:rand_index].numpy()[0][2::3]] + [reverse_mapping[\"len\"][p-sizes[0]-sizes[1]] for p in preds[2::3]]\n",
    "        \n",
    "    return pred_note, pred_off, pred_len\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
